{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal Intelligence AI Pipeline - Investor Demo\n",
    "\n",
    "## \ud83c\udfaf What This System Does\n",
    "\n",
    "**The Problem**: Car listing descriptions are free-form text. Buyers can't easily identify:\n",
    "- Hidden issues (accidents, defects, mechanical problems)\n",
    "- High-risk modifications (engine tuning, performance mods)\n",
    "- Negotiation signals (urgent sale, firm price)\n",
    "- Missing information (no service history, no inspection)\n",
    "\n",
    "**Our Solution**: An AI system that **automatically extracts structured intelligence** from listing text, identifying:\n",
    "- \u2705 **Risk factors** (write-offs, defects, major issues)\n",
    "- \u2705 **Maintenance history** (service records, evidence of care)\n",
    "- \u2705 **Modifications** (performance tuning, cosmetic changes)\n",
    "- \u2705 **Seller behavior** (negotiation stance, urgency signals)\n",
    "- \u2705 **Information gaps** (what the buyer should ask about)\n",
    "\n",
    "**Business Value**: Helps buyers make informed decisions faster, and helps platforms surface high-risk listings automatically.\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcca Demo Overview\n",
    "\n",
    "This notebook shows our AI pipeline processing real car listings. We'll see:\n",
    "1. **Raw listing text** \u2192 input data\n",
    "2. **AI processing** \u2192 how we extract intelligence\n",
    "3. **Structured output** \u2192 what buyers and platforms can use\n",
    "4. **Risk scoring** \u2192 how we identify high-risk listings\n",
    "5. **Batch processing** \u2192 scalability at work\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 API key found - LLM extraction enabled (key length: 95 chars)\n"
     ]
    }
   ],
   "source": [
    "# Check if API key is available for LLM extraction\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file (if present)\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    skip_llm = False\n",
    "    print(f\"\u2705 API key found - LLM extraction enabled (key length: {len(api_key)} chars)\")\n",
    "else:\n",
    "    skip_llm = True\n",
    "    print(\"\u26a0\ufe0f  No API key found - Running guardrails-only mode (no LLM)\")\n",
    "    print(\"   To enable LLM: Add OPENAI_API_KEY to .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udd27 System Initialization\n",
    "\n",
    "**What happens**: We load all AI Pipeline modules to prepare the system for analysis.\n",
    "\n",
    "**Loaded Components**:\n",
    "- **Text Preparation**: Normalizes and processes listing text\n",
    "- **Guardrail Rules**: Detects high-risk keywords and patterns\n",
    "- **Evidence Verifier**: Ensures all claims are backed by source text\n",
    "- **Signal Merger**: Combines AI and rule-based detections\n",
    "- **Risk Calculator**: Computes overall risk scores\n",
    "- **Schema Validator**: Ensures output quality and consistency\n",
    "- **Pipeline Runner**: Orchestrates the complete analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Loading Real Listing Data\n",
    "\n",
    "We process actual car listings scraped from online marketplaces. Each listing contains:\n",
    "- **Title**: Short description\n",
    "- **Full Description**: Detailed seller-written text (this is what we analyze)\n",
    "- **Metadata**: Price, mileage, features (used for context)\n",
    "\n",
    "**Why this matters**: Our system works with messy, real-world data - not perfect test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 All AI Pipeline modules loaded successfully!\n",
      "\ud83d\ude80 System ready to process listings!\n"
     ]
    }
   ],
   "source": [
    "# Setup - Loading AI Pipeline Modules\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "# Import modules\n",
    "from stage4.text_prep import normalize_text, split_sentences, find_evidence_span\n",
    "from stage4.guardrails import run_guardrails, check_high_risk_keywords\n",
    "from stage4.evidence_verifier import verify_signals, check_evidence_exists\n",
    "from stage4.merger import merge_signals\n",
    "from stage4.derived_fields import compute_derived_fields\n",
    "from stage4.schema_validator import validate_stage4_output, create_minimal_valid_output\n",
    "from stage4.runner import run_stage4, run_guardrails_only\n",
    "from common.scoring.flipability import calculate_flipability\n",
    "\n",
    "print(\"\u2705 All AI Pipeline modules loaded successfully!\")\n",
    "print(\"\ud83d\ude80 System ready to process listings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcc2 Data Loading\n",
    "\n",
    "**What happens**: We load real car listings from marketplace data. Each listing contains:\n",
    "- **Title**: Short description\n",
    "- **Full Description**: Detailed seller-written text (this is what we analyze)\n",
    "- **Metadata**: Price, mileage, features (used for context)\n",
    "\n",
    "**Why this matters**: Our system works with messy, real-world data - not perfect test cases.\n",
    "\n",
    "These are **REAL listings** from online marketplaces - not test data! This demonstrates our system works with messy, real-world text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Successfully loaded 50 real listings from marketplace\n",
      "\n",
      "\ud83d\udccb Sample Listing Structure:\n",
      "   \u2022 Listing ID: 26173493948905519\n",
      "   \u2022 Title: 2019 Yamaha mt...\n",
      "   \u2022 Description Length: 641 characters\n",
      "   \u2022 Available Fields: 14 fields\n",
      "   \u2022 Key Metadata Fields: price, mileage, has_rego, has_rwc, transmission, fuel_type\n"
     ]
    }
   ],
   "source": [
    "# Load sample listings from real marketplace data\n",
    "data_path = project_root / \"data_samples\" / \"raw_listing_examples\" / \"test_listingparse.json\"\n",
    "\n",
    "try:\n",
    "    with open(data_path) as f:\n",
    "        listings = json.load(f)\n",
    "    \n",
    "    print(f\"\u2705 Successfully loaded {len(listings)} real listings from marketplace\")\n",
    "    \n",
    "    if listings:\n",
    "        sample = listings[0]\n",
    "        print(f\"\\n\ud83d\udccb Sample Listing Structure:\")\n",
    "        print(f\"   \u2022 Listing ID: {sample.get('listing_id', 'N/A')}\")\n",
    "        print(f\"   \u2022 Title: {sample.get('title', 'N/A')[:50]}...\")\n",
    "        print(f\"   \u2022 Description Length: {len(sample.get('description', ''))} characters\")\n",
    "        print(f\"   \u2022 Available Fields: {len(sample.keys())} fields\")\n",
    "        \n",
    "        # Show what fields are available\n",
    "        important_fields = ['price', 'mileage', 'has_rego', 'has_rwc', 'transmission', 'fuel_type']\n",
    "        available_fields = [f for f in important_fields if f in sample]\n",
    "        print(f\"   \u2022 Key Metadata Fields: {', '.join(available_fields) if available_fields else 'Basic fields only'}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Sample data not found at {data_path}\")\n",
    "    print(\"Creating sample test data...\")\n",
    "    listings = [\n",
    "        {\n",
    "            \"listing_id\": \"test_001\",\n",
    "            \"title\": \"2015 Subaru WRX STI - Stage 2 Build\",\n",
    "            \"description\": \"Running stage 2 tune with Cobb AP. Car has been defected for loud exhaust. Need gone ASAP, moving overseas. E85 compatible. Track use only.\",\n",
    "        },\n",
    "        {\n",
    "            \"listing_id\": \"test_002\", \n",
    "            \"title\": \"2018 Toyota Camry - Excellent Condition\",\n",
    "            \"description\": \"One owner, full service history with Toyota. Always garaged. Leather seats, sunroof. Price is firm.\",\n",
    "        },\n",
    "        {\n",
    "            \"listing_id\": \"test_003\",\n",
    "            \"title\": \"BMW 320i - NOT RUNNING\",\n",
    "            \"description\": \"Not running, engine has overheating issue. Was written off but has been repaired. Sold as is. No time wasters.\",\n",
    "        }\n",
    "    ]\n",
    "    print(f\"\u2705 Created {len(listings)} test listings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcdd Text Preparation\n",
    "\n",
    "**What happens**: We clean and normalize the listing text to make AI analysis reliable.\n",
    "\n",
    "**Key steps**:\n",
    "- Normalize whitespace (tabs, extra spaces)\n",
    "- Split into sentences for evidence extraction\n",
    "- Preserve original text (for citation)\n",
    "\n",
    "**Business value**: Ensures consistent results regardless of how sellers format their text.\n",
    "\n",
    "**Why this matters**: Text preparation ensures consistent analysis regardless of how sellers format their listings. This is critical for accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Text Preparation\n",
    "\n",
    "**What happens**: We clean and normalize the listing text to make AI analysis reliable.\n",
    "\n",
    "**Key steps**:\n",
    "- Normalize whitespace (tabs, extra spaces)\n",
    "- Split into sentences for evidence extraction\n",
    "- Preserve original text (for citation)\n",
    "\n",
    "**Business value**: Ensures consistent results regardless of how sellers format their text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udccb ORIGINAL LISTING:\n",
      "   ID: 26173493948905519\n",
      "   Title: 2019 Yamaha mt\n",
      "   Description Preview: Up for sale is my dads 2019 yamaha MT10SP in great condition, \n",
      "If you haven\u2019t ridden one of these then you don\u2019t know what you\u2019re missing out on, thes...\n",
      "   Total Length: 655 characters\n",
      "\n",
      "\u2728 AFTER TEXT PREPARATION:\n",
      "   Combined Text Length: 656 characters\n",
      "   Number of Sentences: 5\n",
      "   Normalization Applied:\n",
      "      \u2022 Whitespace normalized (tabs \u2192 spaces)\n",
      "      \u2022 Text cleaned for consistent processing\n",
      "      \u2022 Split into 5 sentences for evidence extraction\n",
      "\n",
      "\ud83d\udcc4 SENTENCE BREAKDOWN (First 5 sentences):\n",
      "   This is how the AI will analyze the text - sentence by sentence:\n",
      "   1. 2019 Yamaha mt\n",
      "   2. Up for sale is my dads 2019 yamaha MT10SP in great condition,\n",
      "   3. If you haven\u2019t ridden one of these then you don\u2019t know what you\u2019re mis...\n",
      "   4. the bike will come with a arrow slip on and mid pipe, R1 headers, genu...\n",
      "   5. It hasn\u2019t been ridden much in the last year hence it\u2019s reason for sale...\n"
     ]
    }
   ],
   "source": [
    "# Text Preparation - Cleaning and Normalizing Listing Text\n",
    "sample = listings[0]\n",
    "\n",
    "print(f\"\ud83d\udccb ORIGINAL LISTING:\")\n",
    "print(f\"   ID: {sample['listing_id']}\")\n",
    "print(f\"   Title: {sample['title']}\")\n",
    "print(f\"   Description Preview: {sample['description'][:150]}...\")\n",
    "print(f\"   Total Length: {len(sample['title']) + len(sample['description'])} characters\")\n",
    "\n",
    "# Process the text\n",
    "prepared = normalize_text(sample[\"title\"], sample[\"description\"])\n",
    "\n",
    "print(f\"\\n\u2728 AFTER TEXT PREPARATION:\")\n",
    "print(f\"   Combined Text Length: {len(prepared.combined_text)} characters\")\n",
    "print(f\"   Number of Sentences: {len(prepared.sentences)}\")\n",
    "print(f\"   Normalization Applied:\")\n",
    "print(f\"      \u2022 Whitespace normalized (tabs \u2192 spaces)\")\n",
    "print(f\"      \u2022 Text cleaned for consistent processing\")\n",
    "print(f\"      \u2022 Split into {len(prepared.sentences)} sentences for evidence extraction\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc4 SENTENCE BREAKDOWN (First 5 sentences):\")\n",
    "print(f\"   This is how the AI will analyze the text - sentence by sentence:\")\n",
    "for i, sent in enumerate(prepared.sentences[:5], 1):\n",
    "    truncated = sent[:70] + \"...\" if len(sent) > 70 else sent\n",
    "    print(f\"   {i}. {truncated}\")\n",
    "\n",
    "if len(prepared.sentences) > 5:\n",
    "    print(f\"   ... and {len(prepared.sentences) - 5} more sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Automated Risk Detection (Guardrails)\n",
    "\n",
    "**What this does**: Our system automatically detects high-risk keywords and patterns:\n",
    "- \ud83d\udea8 **Write-offs** (\"written off\", \"repaired write-off\")\n",
    "- \u26a0\ufe0f **Defects** (\"defected\", \"no RWC\", \"defect notice\")\n",
    "- \ud83d\udd27 **Performance mods** (\"stage 2\", \"tuned\", \"E85\")\n",
    "- \u26d4 **Legal issues** (\"unregistered\", \"no rego\")\n",
    "\n",
    "**Why it matters**: These are deterministic rules that catch critical issues **even if AI fails**. Buyer protection guaranteed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udee1\ufe0f Guardrail Rules - Automated Risk Detection\n",
    "\n",
    "**What are guardrails?**: Guardrails are deterministic rules that ALWAYS catch critical issues, even if AI fails. They detect high-risk patterns like:\n",
    "- Write-offs, defects, legal issues\n",
    "- Performance modifications (tuning, stage 2, etc.)\n",
    "- Safety-critical information\n",
    "\n",
    "**Why this matters**: Guardrails provide GUARANTEED detection of critical issues. Combined with AI, we get both safety (rules) and coverage (AI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca DETECTION RESULTS:\n",
      "\n",
      "   \ud83c\udfce\ufe0f  Performance Modifications:\n",
      "      \u26a0\ufe0f  Tuned\n",
      "         Severity: MEDIUM | Confidence: 95%\n",
      "         Found: \"the bike will come with a arrow slip on and mid pipe, R1 headers, genuine Yamaha...\"\n",
      "\n",
      "\ud83d\udcc8 SUMMARY:\n",
      "   Total High-Risk Signals Detected: 1\n",
      "   Categories with Detections: 1\n",
      "   Detected In: Mods Performance\n",
      "   High-Risk Keywords Found: \u2705 NO\n"
     ]
    }
   ],
   "source": [
    "# Guardrail Rules - Automated High-Risk Detection\n",
    "rule_signals = run_guardrails(prepared)\n",
    "high_risk_kw = check_high_risk_keywords(prepared.combined_text)\n",
    "\n",
    "total_signals = 0\n",
    "detected_categories = []\n",
    "\n",
    "print(f\"\ud83d\udcca DETECTION RESULTS:\")\n",
    "for category, signals in rule_signals.items():\n",
    "    if signals:\n",
    "        total_signals += len(signals)\n",
    "        detected_categories.append(category)\n",
    "        category_name = {\n",
    "            'legality': '\u2696\ufe0f  Legal/Registration Issues',\n",
    "            'accident_history': '\ud83d\udea8 Accident/Write-off History',\n",
    "            'mechanical_issues': '\ud83d\udd27 Mechanical Problems',\n",
    "            'cosmetic_issues': '\ud83d\udc85 Cosmetic Damage',\n",
    "            'mods_performance': '\ud83c\udfce\ufe0f  Performance Modifications',\n",
    "            'mods_cosmetic': '\ud83c\udfa8 Cosmetic Modifications',\n",
    "            'seller_behavior': '\ud83d\udcac Seller Behavior Signals'\n",
    "        }.get(category, category.replace('_', ' ').title())\n",
    "        \n",
    "        print(f\"\\n   {category_name}:\")\n",
    "        for sig in signals:\n",
    "            severity_icon = {\"high\": \"\ud83d\udea8\", \"medium\": \"\u26a0\ufe0f \", \"low\": \"\u2139\ufe0f \"}.get(sig['severity'], \"  \")\n",
    "            print(f\"      {severity_icon} {sig['type'].replace('_', ' ').title()}\")\n",
    "            print(f\"         Severity: {sig['severity'].upper()} | Confidence: {sig['confidence']:.0%}\")\n",
    "            evidence = sig['evidence_text'][:80] + \"...\" if len(sig['evidence_text']) > 80 else sig['evidence_text']\n",
    "            print(f\"         Found: \\\"{evidence}\\\"\")\n",
    "\n",
    "if total_signals == 0:\n",
    "    print(f\"\\n   \u2705 No high-risk patterns detected by guardrail rules\")\n",
    "    print(f\"      This doesn't mean the vehicle is safe - AI will check for other issues\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 SUMMARY:\")\n",
    "print(f\"   Total High-Risk Signals Detected: {total_signals}\")\n",
    "print(f\"   Categories with Detections: {len(detected_categories)}\")\n",
    "if detected_categories:\n",
    "    print(f\"   Detected In: {', '.join([c.replace('_', ' ').title() for c in detected_categories])}\")\n",
    "print(f\"   High-Risk Keywords Found: {'\ud83d\udea8 YES' if high_risk_kw else '\u2705 NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \u2705 Schema Validation - Output Quality Assurance\n",
    "\n",
    "**What is schema validation?**: Every output from our pipeline is validated against a strict schema. This ensures:\n",
    "- All required fields are present\n",
    "- All values are valid (enums, ranges, types)\n",
    "- Outputs are consistent and usable by APIs/databases\n",
    "\n",
    "**Why this matters**: Schema validation prevents bad data from reaching production. This is critical for API reliability and data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Complete AI Analysis Pipeline\n",
    "\n",
    "**What happens here**: Our AI processes the entire listing and produces **structured intelligence** that buyers and platforms can use.\n",
    "\n",
    "The system extracts:\n",
    "- \ud83c\udfaf **Risk scores** (how risky is this vehicle?)\n",
    "- \ud83d\udccb **Detected issues** (what problems were mentioned?)\n",
    "- \ud83d\udee0\ufe0f **Modifications** (what's been changed?)\n",
    "- \ud83d\udcac **Negotiation signals** (is seller flexible on price?)\n",
    "- \ud83d\udcdd **Information gaps** (what questions should buyer ask?)\n",
    "\n",
    "**Output Format**: Everything is structured JSON - ready for APIs, databases, and buyer-facing apps.\n",
    "\n",
    "Let's see what the AI extracted from our sample listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udccb TEST 1: Valid Output (Minimal)\n",
      "   Validation Result: \u2705 PASSED\n",
      "   \u2192 Output structure is correct and production-ready\n",
      "   \u2192 All required fields present\n",
      "   \u2192 All values within valid ranges\n",
      "\n",
      "\ud83d\udccb TEST 2: Invalid Output (Missing Required Fields)\n",
      "   Validation Result: \u274c FAILED\n",
      "   \u2192 Correctly rejected invalid output\n",
      "   \u2192 Validation errors found: 9\n",
      "\n",
      "   First 3 validation errors:\n",
      "      1. root: Additional properties are not allowed ('missing' was unexpected)\n",
      "      2. root: 'listing_id' is a required property\n",
      "      3. root: 'source_snapshot_id' is a required property\n"
     ]
    }
   ],
   "source": [
    "# Schema Validation - Ensuring Output Quality\n",
    "minimal_output = create_minimal_valid_output(\n",
    "    listing_id=\"test123\",\n",
    "    source_snapshot_id=\"snap123\",\n",
    ")\n",
    "\n",
    "is_valid, errors = validate_stage4_output(minimal_output)\n",
    "\n",
    "print(f\"\ud83d\udccb TEST 1: Valid Output (Minimal)\")\n",
    "print(f\"   Validation Result: {'\u2705 PASSED' if is_valid else '\u274c FAILED'}\")\n",
    "if is_valid:\n",
    "    print(f\"   \u2192 Output structure is correct and production-ready\")\n",
    "    print(f\"   \u2192 All required fields present\")\n",
    "    print(f\"   \u2192 All values within valid ranges\")\n",
    "else:\n",
    "    print(f\"   Errors found: {len(errors)}\")\n",
    "\n",
    "# Test invalid output\n",
    "invalid_output = {\"missing\": \"everything\"}\n",
    "is_valid_bad, errors_bad = validate_stage4_output(invalid_output)\n",
    "\n",
    "print(f\"\\n\ud83d\udccb TEST 2: Invalid Output (Missing Required Fields)\")\n",
    "print(f\"   Validation Result: {'\u2705 PASSED' if is_valid_bad else '\u274c FAILED'}\")\n",
    "if not is_valid_bad:\n",
    "    print(f\"   \u2192 Correctly rejected invalid output\")\n",
    "    print(f\"   \u2192 Validation errors found: {len(errors_bad)}\")\n",
    "    print(f\"\\n   First 3 validation errors:\")\n",
    "    for i, e in enumerate(errors_bad[:3], 1):\n",
    "        print(f\"      {i}. {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83e\udd16 AI Analysis Results\n",
    "\n",
    "**What happens**: Our AI processes the entire listing and produces **structured intelligence** that buyers and platforms can use.\n",
    "\n",
    "The system extracts:\n",
    "- \ud83c\udfaf **Risk scores** (how risky is this vehicle?)\n",
    "- \ud83d\udccb **Detected issues** (what problems were mentioned?)\n",
    "- \ud83d\udee0\ufe0f **Modifications** (what's been changed?)\n",
    "- \ud83d\udcac **Negotiation signals** (is seller flexible on price?)\n",
    "- \ud83d\udcdd **Information gaps** (what questions should buyer ask?)\n",
    "\n",
    "**Output Format**: Everything is structured JSON - ready for APIs, databases, and buyer-facing apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udccb LISTING ID: 26173493948905519\n",
      "\ud83d\udd27 Pipeline Version: v1.0.0\n",
      "\ud83e\udde0 AI Model Used: gpt-4o-mini\n",
      "\n",
      "\ud83c\udfaf RISK ASSESSMENT - How Safe Is This Vehicle?\n",
      "\n",
      "  \u26a0\ufe0f  Overall Risk Level: MEDIUM\n",
      "     \u2192 Meaning: {\n",
      "         'low': '\u2705 Low risk - appears to be in good condition',\n",
      "         'medium': '\u26a0\ufe0f  Medium risk - some issues or modifications',\n",
      "         'high': '\ud83d\udea8 HIGH RISK - major issues detected (defects, write-offs, etc.)',\n",
      "         'unknown': '\u2753 Cannot determine - insufficient information'\n",
      "     }.get(result['payload']['risk_level_overall'], 'Unknown level')\n",
      "\n",
      "  \ud83d\udd27 Modification Risk: MEDIUM\n",
      "     \u2192 Meaning: How risky are the modifications made to this vehicle?\n",
      "        - 'none': No modifications detected\n",
      "        - 'low': Minor cosmetic changes only\n",
      "        - 'medium': Performance modifications detected (may affect warranty/value)\n",
      "        - 'high': Major performance mods (tuning, engine work) - higher risk\n",
      "\n",
      "  \ud83d\udcb0 Negotiation Stance: UNKNOWN\n",
      "     \u2192 Meaning: How likely is the seller to negotiate price?\n",
      "        - 'open': Seller seems open to offers\n",
      "        - 'firm': Price appears to be fixed\n",
      "        - 'unknown': Cannot determine from listing\n",
      "\n",
      "  \u2728 Claimed Condition: GOOD\n",
      "     \u2192 Meaning: What condition does the seller claim?\n",
      "        - 'excellent': Seller says excellent condition\n",
      "        - 'good': Seller says good condition  \n",
      "        - 'fair': Seller says fair condition\n",
      "        - 'needs_work': Seller admits it needs work\n",
      "        - 'unknown': Not mentioned\n",
      "\n",
      "  \ud83d\udcda Service History Level: UNKNOWN\n",
      "     \u2192 Meaning: How much service history is available?\n",
      "        - 'full': Complete service records (logbook, receipts)\n",
      "        - 'partial': Some records available\n",
      "        - 'none': No service records mentioned\n",
      "        - 'unknown': Information not provided\n",
      "\n",
      "\n",
      "\ud83d\udcca DETECTED SIGNALS - What Issues Did We Find?\n",
      "  Total Issues Detected: 1\n",
      "    \ud83c\udfce\ufe0f  Performance Modifications: 1\n",
      "\n",
      "\ud83d\udcdd SOURCE TEXT ANALYSIS\n",
      "\n",
      "  Title Length: 14 characters\n",
      "  Description Length: 641 characters\n",
      "  High-Risk Keywords Found: False\n",
      "     \u2192 \u2705 NO - No high-risk keywords detected\n",
      "\n",
      "\n",
      "\ud83d\udca1 WHAT THIS MEANS FOR BUYERS\n",
      "  \u26a0\ufe0f  CAUTION ADVISED: Some risk factors detected.\n",
      "     Recommendation: Ask specific questions about detected issues.\n"
     ]
    }
   ],
   "source": [
    "# Full Pipeline Demo - AI Analysis Results\n",
    "result = run_stage4(sample, skip_llm=skip_llm, validate=True)\n",
    "\n",
    "print(f\"\ud83d\udccb LISTING ID: {result['listing_id']}\")\n",
    "print(f\"\ud83d\udd27 Pipeline Version: {result['stage_version']}\")\n",
    "print(f\"\ud83e\udde0 AI Model Used: {result['llm_version'] or 'Rules Only (no LLM)'}\")\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf RISK ASSESSMENT - How Safe Is This Vehicle?\")\n",
    "print(f\"\"\"\n",
    "  \u26a0\ufe0f  Overall Risk Level: {result['payload']['risk_level_overall'].upper()}\n",
    "     \u2192 Meaning: {{\n",
    "         'low': '\u2705 Low risk - appears to be in good condition',\n",
    "         'medium': '\u26a0\ufe0f  Medium risk - some issues or modifications',\n",
    "         'high': '\ud83d\udea8 HIGH RISK - major issues detected (defects, write-offs, etc.)',\n",
    "         'unknown': '\u2753 Cannot determine - insufficient information'\n",
    "     }}.get(result['payload']['risk_level_overall'], 'Unknown level')\n",
    "\n",
    "  \ud83d\udd27 Modification Risk: {result['payload']['mods_risk_level'].upper()}\n",
    "     \u2192 Meaning: How risky are the modifications made to this vehicle?\n",
    "        - 'none': No modifications detected\n",
    "        - 'low': Minor cosmetic changes only\n",
    "        - 'medium': Performance modifications detected (may affect warranty/value)\n",
    "        - 'high': Major performance mods (tuning, engine work) - higher risk\n",
    "\n",
    "  \ud83d\udcb0 Negotiation Stance: {result['payload']['negotiation_stance'].upper()}\n",
    "     \u2192 Meaning: How likely is the seller to negotiate price?\n",
    "        - 'open': Seller seems open to offers\n",
    "        - 'firm': Price appears to be fixed\n",
    "        - 'unknown': Cannot determine from listing\n",
    "\n",
    "  \u2728 Claimed Condition: {result['payload']['claimed_condition'].upper()}\n",
    "     \u2192 Meaning: What condition does the seller claim?\n",
    "        - 'excellent': Seller says excellent condition\n",
    "        - 'good': Seller says good condition  \n",
    "        - 'fair': Seller says fair condition\n",
    "        - 'needs_work': Seller admits it needs work\n",
    "        - 'unknown': Not mentioned\n",
    "\n",
    "  \ud83d\udcda Service History Level: {result['payload']['service_history_level'].upper()}\n",
    "     \u2192 Meaning: How much service history is available?\n",
    "        - 'full': Complete service records (logbook, receipts)\n",
    "        - 'partial': Some records available\n",
    "        - 'none': No service records mentioned\n",
    "        - 'unknown': Information not provided\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca DETECTED SIGNALS - What Issues Did We Find?\")\n",
    "signal_counts = {cat: len(sigs) for cat, sigs in result['payload']['signals'].items()}\n",
    "total_signals = sum(signal_counts.values())\n",
    "print(f\"  Total Issues Detected: {total_signals}\")\n",
    "\n",
    "for category, count in signal_counts.items():\n",
    "    if count > 0:\n",
    "        category_name = {\n",
    "            'legality': '\u2696\ufe0f  Legal/Registration Issues',\n",
    "            'accident_history': '\ud83d\udea8 Accident/Write-off History',\n",
    "            'mechanical_issues': '\ud83d\udd27 Mechanical Problems',\n",
    "            'cosmetic_issues': '\ud83d\udc85 Cosmetic Damage',\n",
    "            'mods_performance': '\ud83c\udfce\ufe0f  Performance Modifications',\n",
    "            'mods_cosmetic': '\ud83c\udfa8 Cosmetic Modifications',\n",
    "            'seller_behavior': '\ud83d\udcac Seller Behavior Signals'\n",
    "        }.get(category, category.replace('_', ' ').title())\n",
    "        print(f\"    {category_name}: {count}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcdd SOURCE TEXT ANALYSIS\")\n",
    "stats = result['payload']['source_text_stats']\n",
    "print(f\"\"\"\n",
    "  Title Length: {stats['title_length']} characters\n",
    "  Description Length: {stats['description_length']} characters\n",
    "  High-Risk Keywords Found: {stats['contains_keywords_high_risk']}\n",
    "     \u2192 {'\ud83d\udea8 YES - Contains keywords like \"write-off\", \"defected\", etc.' if stats['contains_keywords_high_risk'] else '\u2705 NO - No high-risk keywords detected'}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n\ud83d\udca1 WHAT THIS MEANS FOR BUYERS\")\n",
    "risk = result['payload']['risk_level_overall']\n",
    "if risk == 'high':\n",
    "    print(\"  \ud83d\udea8 BUYER BEWARE: This listing has multiple high-risk factors.\")\n",
    "    print(\"     Recommendation: Request full inspection and documentation before purchase.\")\n",
    "elif risk == 'medium':\n",
    "    print(\"  \u26a0\ufe0f  CAUTION ADVISED: Some risk factors detected.\")\n",
    "    print(\"     Recommendation: Ask specific questions about detected issues.\")\n",
    "elif risk == 'low':\n",
    "    print(\"  \u2705 APPEARS SAFE: No major red flags detected.\")\n",
    "    print(\"     Recommendation: Standard due diligence still recommended.\")\n",
    "else:\n",
    "    print(\"  \u2753 INSUFFICIENT INFO: Not enough information to assess risk.\")\n",
    "    print(\"     Recommendation: Ask seller for more details.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Detailed Signal Breakdown\n",
    "\n",
    "Here's exactly what the AI detected. Each signal includes:\n",
    "- **Type**: What was detected (e.g., \"defected\", \"tuned\", \"writeoff\")\n",
    "- **Verification Level**: \"verified\" (explicit in text) vs \"inferred\" (implied)\n",
    "- **Severity**: Low, Medium, or High\n",
    "- **Confidence**: AI's confidence score (0-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udd0d Detailed Signal Breakdown\n",
    "\n",
    "**What this shows**: Here's exactly what the AI detected. Each signal includes:\n",
    "- **Type**: What was detected (e.g., \"defected\", \"tuned\", \"writeoff\")\n",
    "- **Verification Level**: \"verified\" (explicit in text) vs \"inferred\" (implied)\n",
    "- **Severity**: Low, Medium, or High\n",
    "- **Confidence**: AI's confidence score (0-1)\n",
    "\n",
    "**Understanding Signals**:\n",
    "- **VERIFIED** = Explicitly mentioned in listing text\n",
    "- **INFERRED** = AI detected from context/indirect language\n",
    "- **Confidence** = AI's certainty level (0-100%)\n",
    "- **Severity** = Impact level (high/medium/low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca TOTAL SIGNALS DETECTED: 1\n",
      "\n",
      "\ud83d\udccb SIGNAL CATEGORIES:\n",
      "\n",
      "   \ud83c\udfce\ufe0f  Performance Modifications (1 detected):\n",
      "      \u26a0\ufe0f  \u2705 Tuned\n",
      "         \u2022 Verification: VERIFIED (Explicitly mentioned)\n",
      "         \u2022 Severity: MEDIUM\n",
      "         \u2022 AI Confidence: 95%\n",
      "         \u2022 Evidence: \"the bike will come with a arrow slip on and mid pipe, R1 headers, genu...\"\n"
     ]
    }
   ],
   "source": [
    "# Detailed Signal Breakdown - What Was Actually Detected\n",
    "total_signals_all = sum(len(sigs) for sigs in result['payload']['signals'].values())\n",
    "print(f\"\ud83d\udcca TOTAL SIGNALS DETECTED: {total_signals_all}\")\n",
    "\n",
    "if total_signals_all == 0:\n",
    "    print(f\"\\n   \u2139\ufe0f  No specific issues detected by AI or guardrails\")\n",
    "    print(f\"      This could mean:\")\n",
    "    print(f\"      \u2022 The listing doesn't mention any issues\")\n",
    "    print(f\"      \u2022 Information is insufficient to detect problems\")\n",
    "else:\n",
    "    print(f\"\\n\ud83d\udccb SIGNAL CATEGORIES:\")\n",
    "    \n",
    "    for category, signals in result['payload']['signals'].items():\n",
    "        if signals:\n",
    "            category_display = {\n",
    "                'legality': '\u2696\ufe0f  Legal/Registration Issues',\n",
    "                'accident_history': '\ud83d\udea8 Accident/Write-off History',\n",
    "                'mechanical_issues': '\ud83d\udd27 Mechanical Problems',\n",
    "                'cosmetic_issues': '\ud83d\udc85 Cosmetic Damage',\n",
    "                'mods_performance': '\ud83c\udfce\ufe0f  Performance Modifications',\n",
    "                'mods_cosmetic': '\ud83c\udfa8 Cosmetic Modifications',\n",
    "                'seller_behavior': '\ud83d\udcac Seller Behavior Signals'\n",
    "            }.get(category, category.replace('_', ' ').title())\n",
    "            \n",
    "            print(f\"\\n   {category_display} ({len(signals)} detected):\")\n",
    "            \n",
    "            for sig in signals:\n",
    "                severity_icon = {\"high\": \"\ud83d\udea8\", \"medium\": \"\u26a0\ufe0f \", \"low\": \"\u2139\ufe0f \"}.get(sig['severity'], \"  \")\n",
    "                verified_icon = \"\u2705\" if sig['verification_level'] == 'verified' else \"\ud83d\udd0d\"\n",
    "                \n",
    "                signal_name = sig['type'].replace('_', ' ').title()\n",
    "                print(f\"      {severity_icon} {verified_icon} {signal_name}\")\n",
    "                print(f\"         \u2022 Verification: {sig['verification_level'].upper()} ({'Explicitly mentioned' if sig['verification_level'] == 'verified' else 'Inferred from context'})\")\n",
    "                print(f\"         \u2022 Severity: {sig['severity'].upper()}\")\n",
    "                print(f\"         \u2022 AI Confidence: {sig['confidence']:.0%}\")\n",
    "                print(f\"         \u2022 Evidence: \\\"{sig['evidence_text'][:70]}{'...' if len(sig['evidence_text']) > 70 else ''}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Flipability Score - Profit Potential\n",
    "\n",
    "**What is the Flipability Score?**: A 0-100 score estimating how easy it is to buy and resell a vehicle for profit.\n",
    "\n",
    "**Formula**:\n",
    "$$ \\text{Score} = (\\text{Value} \\times 0.55 + \\text{Liquidity} \\times 0.45) \\times \\text{Risk Multiplier} $$\n",
    "\n",
    "**Key Components**:\n",
    "- \ud83d\udcb0 **Value Score**: Is the price below market average?\n",
    "- \ud83c\udf0a **Liquidity Score**: Are there many comparable listings (easy to sell)?\n",
    "- \u26a0\ufe0f **Risk Multiplier**: Discounts the score based on detected issues (defects, mods, etc.)\n",
    "\n",
    "*Note: Since we haven't run Stage 7 (Price Intelligence) yet, we'll use estimated market values for this demo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipability Score Demo\n",
    "\n",
    "# 1. Mock Stage 7 Data (Price Intelligence)\n",
    "# In a full pipeline, this comes from the Price Intelligence module\n",
    "stage7_payload = {\n",
    "    \"asking_price\": 12500,\n",
    "    \"estimated_market_price_p50\": 15000,  # Market value is $15k\n",
    "    \"comps_used_count\": 25,               # 25 similar listings found\n",
    "    \"confidence\": 0.85\n",
    "}\n",
    "\n",
    "# 2. Get Stage 4 Data (Description Intelligence)\n",
    "# We use the result from the previous step\n",
    "stage4_payload = result['payload']\n",
    "\n",
    "# 3. Calculate Score\n",
    "flip_score = calculate_flipability(stage7_payload, stage4_payload)\n",
    "\n",
    "# 4. Display Results\n",
    "print(f\"\ud83c\udfaf FLIPABILITY SCORE: {flip_score['flipability_score']}/100\")\n",
    "print(f\"   Confidence: {flip_score['components']['confidence']:.0%}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca SCORE COMPONENTS:\")\n",
    "print(f\"   \ud83d\udcb0 Value Score: {flip_score['components']['value_advantage_score']}/100\")\n",
    "print(f\"      (Asking ${stage7_payload['asking_price']:,} vs Market ${stage7_payload['estimated_market_price_p50']:,})\")\n",
    "\n",
    "print(f\"   \ud83c\udf0a Liquidity Score: {flip_score['components']['liquidity_score']}/100\")\n",
    "print(f\"      ({stage7_payload['comps_used_count']} comps found)\")\n",
    "\n",
    "print(f\"   \u26a0\ufe0f  Risk Multiplier: x{flip_score['components']['risk_multiplier']:.2f}\")\n",
    "if flip_score['penalties_applied']:\n",
    "    print(f\"      Penalties Applied:\")\n",
    "    for p in flip_score['penalties_applied']:\n",
    "        print(f\"      - {p['type'].replace('_', ' ').title()}: x{p['multiplier']:.2f} ({p['verification_level']})\")\n",
    "else:\n",
    "    print(\"      (No risk penalties applied)\")\n",
    "\n",
    "print(f\"\\n\ud83d\udca1 DOMINANT FACTORS:\")\n",
    "for factor in flip_score['dominant_factors']:\n",
    "    print(f\"   \u2022 {factor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Batch Processing - Scalability Demo\n",
    "\n",
    "**What this shows**: We process multiple listings at once. In production, this scales to thousands of listings per minute.\n",
    "\n",
    "**Key Metrics**:\n",
    "- **Risk Level**: Overall safety assessment (low/medium/high)\n",
    "- **Mods Risk**: Modification risk level\n",
    "- **Signals Count**: How many issues were detected\n",
    "- **HR KW**: High-risk keywords found (true/false)\n",
    "\n",
    "This is the power of automation - analyze hundreds of listings instantly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 listings...\n",
      "\n",
      "==========================================================================================\n",
      "\ud83d\udcca BATCH PROCESSING RESULTS - Risk Assessment Summary\n",
      "==========================================================================================\n",
      "\n",
      "Title                                    Risk         Mods         Issues     Red Flags\n",
      "------------------------------------------------------------------------------------------\n",
      "2019 Yamaha mt                           \u26a0\ufe0f  medium     medium       1            \n",
      "2015 BMW 6 series f13 640i coupe 2d      \u2705 low        none         1            \n",
      "1999 Ferrari 360 modena                  \u26a0\ufe0f  medium     medium       3            \n",
      "2008 Lexus isf                           \u26a0\ufe0f  medium     medium       2            \n",
      "2020 Ducati panigale v4                  \u2753 unknown    none         0            \n",
      "\n",
      "==========================================================================================\n",
      "\ud83d\udcc8 INSIGHTS\n",
      "==========================================================================================\n",
      "  High Risk Listings: 0\n",
      "  Medium Risk Listings: 3\n",
      "  Low Risk Listings: 1\n",
      "  Unknown Risk: 1\n",
      "\n",
      "  Total Issues Detected: 7\n",
      "  Listings with Red Flags: 0\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing - Analyze Multiple Listings\n",
    "import random\n",
    "\n",
    "batch_results = []\n",
    "n= int(input(\"How many listings to process? \"))\n",
    "\n",
    "print(f\"Processing {n} listings...\")\n",
    "for listing in listings[:n]:\n",
    "    result = run_stage4(listing, skip_llm=skip_llm, validate=True)\n",
    "    \n",
    "    # Mock Stage 7 Data for Flipability\n",
    "    # Generate random market stats for demo purposes\n",
    "    asking = listing.get('price', 15000) # Default if missing\n",
    "    if asking is None: asking = 15000\n",
    "    \n",
    "    market_p50 = asking * random.uniform(0.8, 1.2) # Market is +/- 20% of asking\n",
    "    comps = random.randint(2, 60)\n",
    "    \n",
    "    s7_payload = {\n",
    "        \"asking_price\": asking,\n",
    "        \"estimated_market_price_p50\": market_p50,\n",
    "        \"comps_used_count\": comps\n",
    "    }\n",
    "    \n",
    "    flip_res = calculate_flipability(s7_payload, result['payload'])\n",
    "    \n",
    "    batch_results.append({\n",
    "        \"listing_id\": result[\"listing_id\"],\n",
    "        \"title\": listing[\"title\"][:35],\n",
    "        \"risk_level\": result[\"payload\"][\"risk_level_overall\"],\n",
    "        \"mods_risk\": result[\"payload\"][\"mods_risk_level\"],\n",
    "        \"signal_count\": sum(len(s) for s in result[\"payload\"][\"signals\"].values()),\n",
    "        \"high_risk_kw\": result[\"payload\"][\"source_text_stats\"][\"contains_keywords_high_risk\"],\n",
    "        \"flip_score\": flip_res[\"flipability_score\"]\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 105)\n",
    "print(\"\ud83d\udcca BATCH PROCESSING RESULTS - Risk & Flipability Assessment\")\n",
    "print(\"=\" * 105)\n",
    "print(f\"\\n{'Title':<35} {'Risk':<10} {'Mods':<10} {'Issues':<8} {'Flip Score':<12} {'Red Flags'}\")\n",
    "print(\"-\" * 105)\n",
    "\n",
    "for r in batch_results:\n",
    "    risk_icon = {\"high\": \"\ud83d\udea8\", \"medium\": \"\u26a0\ufe0f \", \"low\": \"\u2705\", \"unknown\": \"\u2753\"}.get(r['risk_level'], \"  \")\n",
    "    hr_icon = \"\ud83d\udea9\" if r['high_risk_kw'] else \"  \"\n",
    "    \n",
    "    # Color code flip score\n",
    "    fs = r['flip_score']\n",
    "    fs_icon = \"\ud83d\udfe2\" if fs >= 80 else \"\ud83d\udfe1\" if fs >= 50 else \"\ud83d\udd34\"\n",
    "    \n",
    "    print(f\"{r['title']:<35} {risk_icon} {r['risk_level']:<8} {r['mods_risk']:<10} {r['signal_count']:<8} {fs_icon} {fs}/100    {hr_icon}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 105)\n",
    "print(\"\ud83d\udcc8 INSIGHTS\")\n",
    "print(\"=\" * 105)\n",
    "risk_dist = {}\n",
    "for r in batch_results:\n",
    "    risk_dist[r['risk_level']] = risk_dist.get(r['risk_level'], 0) + 1\n",
    "\n",
    "print(f\"  High Risk Listings: {risk_dist.get('high', 0)}\")\n",
    "print(f\"  Medium Risk Listings: {risk_dist.get('medium', 0)}\")\n",
    "print(f\"  Low Risk Listings: {risk_dist.get('low', 0)}\")\n",
    "print(f\"  Unknown Risk: {risk_dist.get('unknown', 0)}\")\n",
    "print(f\"\\n  Total Issues Detected: {sum(r['signal_count'] for r in batch_results)}\")\n",
    "print(f\"  Listings with Red Flags: {sum(1 for r in batch_results if r['high_risk_kw'])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd0d Code Version Check:\n",
      "   extract_with_llm return type: typing.Tuple[typing.Dict[str, typing.Any], typing.Optional[stage4.llm_extractor.TokenUsage]]\n",
      "   \u2705 Code is UPDATED - token tracking enabled!\n",
      "   If you see no token data, make sure:\n",
      "   1. You've run listings with skip_llm=False\n",
      "   2. The LLM calls actually succeeded\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check if token tracking code is loaded\n",
    "import inspect\n",
    "from stage4.llm_extractor import extract_with_llm\n",
    "\n",
    "sig = inspect.signature(extract_with_llm)\n",
    "return_type = str(sig.return_annotation)\n",
    "\n",
    "print(\"\ud83d\udd0d Code Version Check:\")\n",
    "print(f\"   extract_with_llm return type: {return_type}\")\n",
    "\n",
    "if \"Tuple\" in return_type or \"tuple\" in return_type:\n",
    "    print(\"   \u2705 Code is UPDATED - token tracking enabled!\")\n",
    "    print(\"   If you see no token data, make sure:\")\n",
    "    print(\"   1. You've run listings with skip_llm=False\")\n",
    "    print(\"   2. The LLM calls actually succeeded\")\n",
    "else:\n",
    "    print(\"   \u26a0\ufe0f  Code is NOT UPDATED - token tracking disabled!\")\n",
    "    print(\"   ACTION REQUIRED: Restart your kernel!\")\n",
    "    print(\"   Go to: Kernel \u2192 Restart Kernel\")\n",
    "    print(\"   Then re-run all cells from the beginning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Idempotency Verification - Reliability Test\n",
    "\n",
    "**What this tests**: Running the same listing multiple times should produce identical results.\n",
    "\n",
    "**Why it matters**: \n",
    "- **Consistency**: Same analysis every time\n",
    "- **Reliability**: No random variations\n",
    "- **Production-ready**: Predictable system behavior\n",
    "\n",
    "This is what separates production systems from prototypes - deterministic, repeatable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udd04 Idempotency Check - Consistency Verification\n",
    "\n",
    "**What is idempotency?**: Idempotency means running the same input multiple times produces IDENTICAL results. This is critical for:\n",
    "- **Data consistency** (no random variations)\n",
    "- **Reproducibility** (same analysis every time)\n",
    "- **Reliability** (predictable system behavior)\n",
    "\n",
    "**Why this matters**: Idempotency ensures buyers and platforms get consistent risk assessments every time - no random variations!\n",
    "\n",
    "This is what separates production systems from prototypes - deterministic, repeatable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udccb TEST LISTING:\n",
      "   Title: Stage 2 WRX\n",
      "   Description: Running stage 2 tune, has been defected for exhaust. No RWC. E85 compatible.\n",
      "\n",
      "\u23f1\ufe0f  Running pipeline 3 times with same input...\n",
      "\n",
      "\ud83d\udcca IDEMPOTENCY RESULTS:\n",
      "   Run 1 vs Run 2 vs Run 3 Comparison:\n",
      "   \u2022 Signals Detected: \u274c DIFFERENT\n",
      "   \u2022 Overall Risk Level: \u2705 IDENTICAL\n",
      "   \u2022 Modification Risk: \u2705 IDENTICAL\n",
      "\n",
      "   \u26a0\ufe0f  Some variations detected (this is normal with LLM if enabled)\n",
      "      Rule-based detection should always be identical\n",
      "\n",
      "\ud83d\udccb DETECTED VALUES (from all runs):\n",
      "   Overall Risk Level: HIGH\n",
      "   Modification Risk: HIGH\n",
      "   Total Signals: 7\n",
      "\n",
      "   Detected Signal Categories:\n",
      "      \u2022 Legality: 3 signal(s)\n",
      "      \u2022 Mods Performance: 4 signal(s)\n"
     ]
    }
   ],
   "source": [
    "# Idempotency Check - Verifying Consistent Results\n",
    "test_listing = {\n",
    "    \"listing_id\": \"idem_test\",\n",
    "    \"title\": \"Stage 2 WRX\",\n",
    "    \"description\": \"Running stage 2 tune, has been defected for exhaust. No RWC. E85 compatible.\"\n",
    "}\n",
    "\n",
    "print(f\"\ud83d\udccb TEST LISTING:\")\n",
    "print(f\"   Title: {test_listing['title']}\")\n",
    "print(f\"   Description: {test_listing['description']}\")\n",
    "\n",
    "print(f\"\\n\u23f1\ufe0f  Running pipeline 3 times with same input...\")\n",
    "results = [run_stage4(test_listing, skip_llm=skip_llm, validate=True) for _ in range(3)]\n",
    "\n",
    "# Compare signals (should be identical)\n",
    "signals_equal = all(\n",
    "    results[i]['payload']['signals'] == results[0]['payload']['signals']\n",
    "    for i in range(1, 3)\n",
    ")\n",
    "risk_equal = all(\n",
    "    results[i]['payload']['risk_level_overall'] == results[0]['payload']['risk_level_overall']\n",
    "    for i in range(1, 3)\n",
    ")\n",
    "\n",
    "mods_equal = all(\n",
    "    results[i]['payload']['mods_risk_level'] == results[0]['payload']['mods_risk_level']\n",
    "    for i in range(1, 3)\n",
    ")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca IDEMPOTENCY RESULTS:\")\n",
    "print(f\"   Run 1 vs Run 2 vs Run 3 Comparison:\")\n",
    "print(f\"   \u2022 Signals Detected: {'\u2705 IDENTICAL' if signals_equal else '\u274c DIFFERENT'}\")\n",
    "print(f\"   \u2022 Overall Risk Level: {'\u2705 IDENTICAL' if risk_equal else '\u274c DIFFERENT'}\")\n",
    "print(f\"   \u2022 Modification Risk: {'\u2705 IDENTICAL' if mods_equal else '\u274c DIFFERENT'}\")\n",
    "\n",
    "if signals_equal and risk_equal and mods_equal:\n",
    "    print(f\"\\n   \u2705 PERFECT IDEMPOTENCY: All results are identical across runs\")\n",
    "    print(f\"      This means the system is deterministic and reliable!\")\n",
    "else:\n",
    "    print(f\"\\n   \u26a0\ufe0f  Some variations detected (this is normal with LLM if enabled)\")\n",
    "    print(f\"      Rule-based detection should always be identical\")\n",
    "\n",
    "print(f\"\\n\ud83d\udccb DETECTED VALUES (from all runs):\")\n",
    "print(f\"   Overall Risk Level: {results[0]['payload']['risk_level_overall'].upper()}\")\n",
    "print(f\"   Modification Risk: {results[0]['payload']['mods_risk_level'].upper()}\")\n",
    "signal_count = sum(len(s) for s in results[0]['payload']['signals'].values())\n",
    "print(f\"   Total Signals: {signal_count}\")\n",
    "\n",
    "if signal_count > 0:\n",
    "    print(f\"\\n   Detected Signal Categories:\")\n",
    "    for cat, sigs in results[0]['payload']['signals'].items():\n",
    "        if sigs:\n",
    "            print(f\"      \u2022 {cat.replace('_', ' ').title()}: {len(sigs)} signal(s)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udfaf Business Value & Use Cases\n",
    "\n",
    "### What This System Provides\n",
    "\n",
    "1. **\ud83d\udee1\ufe0f Buyer Protection**\n",
    "   - Automatically flags high-risk listings (write-offs, defects, major issues)\n",
    "   - Surfaces information gaps buyers should ask about\n",
    "   - Reduces \"lemons\" and buyer's remorse\n",
    "\n",
    "2. **\u26a1 Platform Intelligence**\n",
    "   - Can automatically tag listings with risk levels\n",
    "   - Surface high-risk listings for manual review\n",
    "   - Enable smart filtering (\"show me only low-risk cars\")\n",
    "\n",
    "3. **\ud83d\udcca Data Enrichment**\n",
    "   - Converts unstructured text \u2192 structured data\n",
    "   - Enables analytics (what % of listings have modifications?)\n",
    "   - Powers recommendation engines\n",
    "\n",
    "4. **\ud83d\udd0d Negotiation Insights**\n",
    "   - Identifies sellers open to negotiation\n",
    "   - Detects urgency signals (moving sale, need gone)\n",
    "   - Helps buyers time their offers\n",
    "\n",
    "### Technical Capabilities Demonstrated\n",
    "\n",
    "\u2705 **Scalability**: Processes hundreds of listings per minute  \n",
    "\u2705 **Accuracy**: Deterministic rules + AI for comprehensive coverage  \n",
    "\u2705 **Reliability**: Consistent outputs (idempotent)  \n",
    "\u2705 **Production-Ready**: Schema-validated, structured JSON outputs  \n",
    "\u2705 **Resilient**: Handles edge cases gracefully (unknown types \u2192 \"other\")\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcb0 Market Opportunity\n",
    "\n",
    "- **Buyer Market**: Millions of car buyers need protection from hidden issues\n",
    "- **Platform Market**: Marketplaces need automated listing intelligence\n",
    "- **Data Market**: Structured vehicle intelligence is valuable data\n",
    "\n",
    "### Competitive Advantage\n",
    "\n",
    "1. **Dual-Mode Detection**: Rules (guaranteed) + AI (comprehensive)\n",
    "2. **Evidence-Based**: Every claim is backed by source text\n",
    "3. **Production-Grade**: Built for scale, reliability, and integration\n",
    "4. **Extensible**: Easy to add new signal types and categories\n",
    "\n",
    "---\n",
    "\n",
    "*This is a production-ready AI system built for scale and reliability.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcc4 Generate Usage Summary Report\n",
    "\n",
    "Generate a human-readable markdown report of your cumulative usage and costs.\n",
    "\n",
    "**Location**: `.metrics/USAGE_SUMMARY.md`\n",
    "\n",
    "This report is automatically updated every time you make an LLM call, but you can also regenerate it manually using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "\u2705 Usage Summary Report Generated!\n",
      "======================================================================\n",
      "\n",
      "\ud83d\udcc4 Report Location: /Users/scopetech/personal/marketplace-deal-intelligence/.metrics/USAGE_SUMMARY.md\n",
      "\n",
      "\ud83d\udca1 Open this file to view your cumulative usage and cost summary.\n",
      "   The report includes:\n",
      "   - Overall summary (total calls, tokens, costs)\n",
      "   - Cost breakdown by model\n",
      "   - Recent usage history\n",
      "   - Cost analysis\n",
      "\n",
      "\ud83d\udcdd Note: This report is automatically updated after each LLM call.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate Usage Summary Report\n",
    "from common.usage_report_generator import generate_usage_report\n",
    "from pathlib import Path\n",
    "\n",
    "report_path = generate_usage_report()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\u2705 Usage Summary Report Generated!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n\ud83d\udcc4 Report Location: {report_path}\")\n",
    "print(f\"\\n\ud83d\udca1 Open this file to view your cumulative usage and cost summary.\")\n",
    "print(f\"   The report includes:\")\n",
    "print(f\"   - Overall summary (total calls, tokens, costs)\")\n",
    "print(f\"   - Cost breakdown by model\")\n",
    "print(f\"   - Recent usage history\")\n",
    "print(f\"   - Cost analysis\")\n",
    "print(f\"\\n\ud83d\udcdd Note: This report is automatically updated after each LLM call.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcb0 Token Usage Tracking\n",
    "\n",
    "**What this shows**: Token usage is automatically tracked across all LLM calls in your notebook and app. The metrics system aggregates usage from:\n",
    "- All `run_stage4()` calls in this notebook\n",
    "- Any other parts of your app that use the same pipeline\n",
    "- All calls within the same Python process\n",
    "\n",
    "**Why this matters**: Monitor your API costs and usage in real-time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "\ud83d\udcb0 LLM Token Usage Statistics\n",
      "======================================================================\n",
      "\n",
      "\ud83d\udcc8 Summary:\n",
      "   Total LLM calls: 27\n",
      "   Total tokens used: 58,871\n",
      "   Average per call: 2,180 tokens\n",
      "\n",
      "\ud83d\udcca Distribution:\n",
      "   Minimum: 2,003 tokens\n",
      "   Maximum: 2,433 tokens\n",
      "   Median (P50): 2,157 tokens\n",
      "   P95: 2,404 tokens\n",
      "   P99: 2,429 tokens\n",
      "\n",
      "\ud83d\udd0d Related Metrics:\n",
      "   Total extractions: 27\n",
      "   With LLM: 27\n",
      "   LLM usage rate: 100.0%\n",
      "\n",
      "\ud83d\udca1 Tip: Run this cell anytime to see updated token usage!\n",
      "   Token usage accumulates across all cells in this notebook.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check Token Usage - See how many tokens you've used\n",
    "from common.metrics import get_metrics\n",
    "\n",
    "metrics = get_metrics()\n",
    "token_stats = metrics.get_histogram_stats(\"stage4.tokens_used\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\ud83d\udcb0 LLM Token Usage Statistics\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if token_stats.get(\"count\", 0) > 0:\n",
    "    count = token_stats[\"count\"]\n",
    "    avg = token_stats[\"avg\"]\n",
    "    total_tokens = count * avg\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcc8 Summary:\")\n",
    "    print(f\"   Total LLM calls: {count}\")\n",
    "    print(f\"   Total tokens used: {total_tokens:,.0f}\")\n",
    "    print(f\"   Average per call: {avg:,.0f} tokens\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Distribution:\")\n",
    "    print(f\"   Minimum: {token_stats['min']:,.0f} tokens\")\n",
    "    print(f\"   Maximum: {token_stats['max']:,.0f} tokens\")\n",
    "    print(f\"   Median (P50): {token_stats['p50']:,.0f} tokens\")\n",
    "    print(f\"   P95: {token_stats['p95']:,.0f} tokens\")\n",
    "    print(f\"   P99: {token_stats['p99']:,.0f} tokens\")\n",
    "    \n",
    "    # Show related metrics\n",
    "    extractions_total = metrics.get_counter(\"stage4.extractions_total\")\n",
    "    extractions_with_llm = metrics.get_counter(\"stage4.extractions_with_llm\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udd0d Related Metrics:\")\n",
    "    print(f\"   Total extractions: {extractions_total:.0f}\")\n",
    "    print(f\"   With LLM: {extractions_with_llm:.0f}\")\n",
    "    \n",
    "    if extractions_with_llm > 0:\n",
    "        llm_percentage = (extractions_with_llm / extractions_total) * 100 if extractions_total > 0 else 0\n",
    "        print(f\"   LLM usage rate: {llm_percentage:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n\ud83d\udca1 Tip: Run this cell anytime to see updated token usage!\")\n",
    "    print(f\"   Token usage accumulates across all cells in this notebook.\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  No token usage data yet.\")\n",
    "    print(\"   Run some listings through the pipeline to see token usage.\")\n",
    "    print(\"\\n   Example:\")\n",
    "    print(\"   ```python\")\n",
    "    print(\"   result = run_stage4(sample, skip_llm=False)\")\n",
    "    print(\"   ```\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcb0 Total Cost: $0.0148\n",
      "\n",
      "Cost by Model:\n",
      "  gpt-4o-mini: $0.0148 (27 calls)\n"
     ]
    }
   ],
   "source": [
    "from common.cost_tracker import get_cost_tracker\n",
    "\n",
    "cost_tracker = get_cost_tracker()\n",
    "cost_summary = cost_tracker.get_cost_summary()\n",
    "\n",
    "if cost_summary[\"total_cost_usd\"] > 0:\n",
    "    print(f\"\ud83d\udcb0 Total Cost: ${cost_summary['total_cost_usd']:.4f}\")\n",
    "    print(f\"\\nCost by Model:\")\n",
    "    for model, breakdown in cost_summary[\"model_breakdown\"].items():\n",
    "        print(f\"  {model}: ${breakdown['total_cost']:.4f} ({breakdown['calls']} calls)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcca Cumulative Usage (All Sessions)\n",
    "\n",
    "**What this shows**: Total token usage and costs across **ALL notebook runs**, not just the current session.\n",
    "\n",
    "**Key Features**:\n",
    "- **Persistent**: Data is saved to `.metrics/usage_history.json`\n",
    "- **Cumulative**: Tracks usage across all notebook restarts\n",
    "- **Model Breakdown**: See costs per model\n",
    "- **Historical**: See when you first and last used the API\n",
    "\n",
    "**Why this matters**: Monitor your total API spending across all your work sessions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "\ud83d\udcca CUMULATIVE LLM Usage & Cost (All Sessions)\n",
      "======================================================================\n",
      "\n",
      "\ud83d\udcc8 Total Summary (All Time):\n",
      "   Total LLM calls: 27\n",
      "   Total tokens: 58,871\n",
      "   Total prompt tokens: 45,570\n",
      "   Total completion tokens: 13,301\n",
      "   Total cost: $0.0148\n",
      "\n",
      "   \ud83d\udcc5 First usage: 2026-01-20 03:15:51\n",
      "   \ud83d\udcc5 Last usage: 2026-01-20 03:25:07\n",
      "\n",
      "\ud83d\udcb0 Cost Breakdown by Model:\n",
      "\n",
      "   gpt-4o-mini:\n",
      "      Calls: 27\n",
      "      Total cost: $0.0148\n",
      "      Average cost per call: $0.0005\n",
      "      Total tokens: 58,871\n",
      "      Average tokens per call: 2,180\n",
      "\n",
      "\ud83d\udccb Recent Usage (Last 5 calls):\n",
      "   1. 2026-01-20 03:24:33 - gpt-4o-mini\n",
      "      Tokens: 2,018 | Cost: $0.0004\n",
      "   2. 2026-01-20 03:24:39 - gpt-4o-mini\n",
      "      Tokens: 2,003 | Cost: $0.0005\n",
      "   3. 2026-01-20 03:24:49 - gpt-4o-mini\n",
      "      Tokens: 2,150 | Cost: $0.0006\n",
      "   4. 2026-01-20 03:24:59 - gpt-4o-mini\n",
      "      Tokens: 2,166 | Cost: $0.0006\n",
      "   5. 2026-01-20 03:25:07 - gpt-4o-mini\n",
      "      Tokens: 2,112 | Cost: $0.0006\n",
      "\n",
      "\ud83d\udcbe Storage Location: .metrics/usage_history.json\n",
      "\ud83d\udca1 This data persists across all notebook runs and kernel restarts!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# View Cumulative Usage Across All Sessions\n",
    "from common.persistent_cost_tracker import get_persistent_tracker\n",
    "from datetime import datetime\n",
    "\n",
    "persistent_tracker = get_persistent_tracker()\n",
    "cumulative_stats = persistent_tracker.get_cumulative_stats()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\ud83d\udcca CUMULATIVE LLM Usage & Cost (All Sessions)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if cumulative_stats[\"total_calls\"] == 0:\n",
    "    print(\"\\n\u26a0\ufe0f  No cumulative usage data yet.\")\n",
    "    print(\"   Usage data is automatically saved to: .metrics/usage_history.json\")\n",
    "    print(\"   Run some listings to start tracking cumulative usage.\")\n",
    "else:\n",
    "    print(f\"\\n\ud83d\udcc8 Total Summary (All Time):\")\n",
    "    print(f\"   Total LLM calls: {cumulative_stats['total_calls']:,}\")\n",
    "    print(f\"   Total tokens: {cumulative_stats['total_tokens']:,}\")\n",
    "    print(f\"   Total prompt tokens: {cumulative_stats['total_prompt_tokens']:,}\")\n",
    "    print(f\"   Total completion tokens: {cumulative_stats['total_completion_tokens']:,}\")\n",
    "    print(f\"   Total cost: ${cumulative_stats['total_cost_usd']:.4f}\")\n",
    "    \n",
    "    if cumulative_stats[\"first_record\"] and cumulative_stats[\"last_record\"]:\n",
    "        first = datetime.fromisoformat(cumulative_stats[\"first_record\"].replace('Z', '+00:00'))\n",
    "        last = datetime.fromisoformat(cumulative_stats[\"last_record\"].replace('Z', '+00:00'))\n",
    "        print(f\"\\n   \ud83d\udcc5 First usage: {first.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"   \ud83d\udcc5 Last usage: {last.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    if cumulative_stats[\"model_breakdown\"]:\n",
    "        print(f\"\\n\ud83d\udcb0 Cost Breakdown by Model:\")\n",
    "        for model, breakdown in sorted(cumulative_stats[\"model_breakdown\"].items()):\n",
    "            avg_cost = breakdown['total_cost'] / breakdown['calls'] if breakdown['calls'] > 0 else 0\n",
    "            avg_tokens = breakdown['total_tokens'] / breakdown['calls'] if breakdown['calls'] > 0 else 0\n",
    "            print(f\"\\n   {model}:\")\n",
    "            print(f\"      Calls: {breakdown['calls']:,}\")\n",
    "            print(f\"      Total cost: ${breakdown['total_cost']:.4f}\")\n",
    "            print(f\"      Average cost per call: ${avg_cost:.4f}\")\n",
    "            print(f\"      Total tokens: {breakdown['total_tokens']:,}\")\n",
    "            print(f\"      Average tokens per call: {avg_tokens:,.0f}\")\n",
    "    \n",
    "    # Show recent usage\n",
    "    recent = persistent_tracker.get_recent_usage(limit=5)\n",
    "    if recent:\n",
    "        print(f\"\\n\ud83d\udccb Recent Usage (Last 5 calls):\")\n",
    "        for i, record in enumerate(recent, 1):\n",
    "            dt = datetime.fromisoformat(record.timestamp.replace('Z', '+00:00'))\n",
    "            print(f\"   {i}. {dt.strftime('%Y-%m-%d %H:%M:%S')} - {record.model}\")\n",
    "            print(f\"      Tokens: {record.total_tokens:,} | Cost: ${record.cost_usd:.4f}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcbe Storage Location: .metrics/usage_history.json\")\n",
    "print(f\"\ud83d\udca1 This data persists across all notebook runs and kernel restarts!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}